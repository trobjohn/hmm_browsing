{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sparse matrix representation of the data...\n",
      "Total blocks:  1566 \n",
      "\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os as os\n",
    "import pandas as pd\n",
    "#import polars as pl\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "import seaborn as sns\n",
    "import pickle, random, re\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "POOL_SIZE = 20  # Rivanna cores, about 25\n",
    "LOAD_SIZE = 20\n",
    "PROPORTION = .025\n",
    "TOP_SITE_LIMIT = 100\n",
    "\n",
    "rivanna_path = '/scratch/trj2j/hmm/u_paths/'\n",
    "\n",
    "## Sites and users:\n",
    "rolo_s = pd.read_csv('./sweep/rolodex_sites.csv')['sites']\n",
    "rolo_u = pd.read_csv('./sweep/rolodex_u.csv')['user'].to_list()\n",
    "\n",
    "## Target sites: top sights and focus sights\n",
    "target = pd.read_csv('./data/news.csv')['domain']\n",
    "top = pd.read_csv('./data/top_sites.csv')['domain']\n",
    "top = top[:TOP_SITE_LIMIT]\n",
    "focus = pd.concat([target,top]) # The labels for k, focus sites\n",
    "rolo_s = list(set(rolo_s) - set(focus)) # The labels for j, idio sites\n",
    "focus = list(focus)\n",
    "K = len(focus) # Number of focus sites\n",
    "J = len(rolo_s) # Total number of sites\n",
    "\n",
    "pickle.dump(rolo_s, open('./sweep/rolo_s_clean.pickle', 'wb'))\n",
    "    #rolo_s = pickle.load(open('./models/rolo_s_clean.pickle','rb'))\n",
    "\n",
    "## Take a large random sample of users. Otherwise this will never finish. //63623\n",
    "random.seed(632623)\n",
    "rolo_u = random.sample(rolo_u, int(len(rolo_u)*PROPORTION) )\n",
    "I = len(rolo_u) # Number of users\n",
    "\n",
    "## Create sparse matrix version in lil format\n",
    "print('Creating sparse matrix representation of the data...')\n",
    "N_blocks = int( np.floor(I/LOAD_SIZE))\n",
    "print('Total blocks: ', N_blocks, '\\n')\n",
    "#u_blocks = np.array(rolo_u[:N_blocks*LOAD_SIZE]).reshape(N_blocks,LOAD_SIZE)\n",
    "u_blocks= [ rolo_u[k*LOAD_SIZE : (k+1)*LOAD_SIZE] for k in range(int(len(rolo_u)/LOAD_SIZE))]\n",
    "\n",
    "N_blocks = len(u_blocks)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "h_paths = os.listdir('/scratch/trj2j/hmm/h')\n",
    "in_vals = []\n",
    "out_vals = []\n",
    "\n",
    "for h in h_paths:\n",
    "    temp = re.split('[_.]', h)\n",
    "    if temp[1] == 'in':\n",
    "        in_vals.append(temp[2])\n",
    "    elif temp[1] == 'out':\n",
    "        out_vals.append(temp[2])\n",
    "\n",
    "all = [str(i) for i in range(N_blocks)]\n",
    "\n",
    "in_remainder = list(set(all)-set(in_vals))\n",
    "out_remainder = list(set(all)-set(out_vals))        \n",
    "\n",
    "print(in_remainder) # []\n",
    "print(out_remainder) # ['629', '1455']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_u_block(block_number):\n",
    "    print('Processing block: ', block_number, flush=True)\n",
    "    assignment = pickle.load(open('/scratch/trj2j/hmm/site_allocations/assignment_'+str(block_number)+'.pickle','rb'))\n",
    "    this_block = assignment['this_block']\n",
    "    focus = assignment['focus']\n",
    "    K = len(focus)\n",
    "    rolo_s = assignment['rolo_s']\n",
    "    J = len(rolo_s)\n",
    "    path = \"/scratch/trj2j/hmm/u_paths/\"\n",
    "\n",
    "    ## Prep\n",
    "    h_in_block = lil_matrix((J,K), dtype=int) # other, focus\n",
    "    h_out_block = lil_matrix((J,K), dtype=int)\n",
    "\n",
    "    # Get all users in the block at once\n",
    "    these_paths = pd.DataFrame()\n",
    "    for u in this_block:\n",
    "        # Skip the really large path files    \n",
    "        path = \"/scratch/trj2j/hmm/u_paths/\"\n",
    "        file = 'path_'+str(u)+'.csv'\n",
    "        this_size = os.stat(os.path.join(path,file)).st_size\n",
    "        if this_size < 3000000: #4900000\n",
    "            user_path = pd.read_csv(path+file,low_memory=False)\n",
    "            these_paths = pd.concat([these_paths, user_path],axis=0)\n",
    "    ######################################################################################################\n",
    "    ## ARRIVAL ANALYSIS\n",
    "    arrivals = pd.crosstab(these_paths['domain'],these_paths['from'])\n",
    "    # Shrink arrival rows to focus\n",
    "    row_names = arrivals.index.to_list()\n",
    "    col_names = arrivals\n",
    "    r_select = [ i in focus for i in row_names ] # Select only focus sites from rows of arrival\n",
    "    c_select = [ i not in focus for i in col_names ] # Select only focus sites from rows of arrival\n",
    "    arr = arrivals.iloc[r_select,c_select] # Shrink to focus sites\n",
    "    row_names = arr.index.to_list()\n",
    "    col_names = arr.columns\n",
    "    # Locate in larger array\n",
    "    focus_locate = [ focus.index(i) for i in row_names ] # focus sites\n",
    "    idio_locate = [ rolo_s.index(i) for i in col_names] # idio sites -- This is the major time cost\n",
    "    # Place values in h_:\n",
    "    for f in range(len(focus_locate)): # focus\n",
    "        c = focus_locate[f]\n",
    "        for i in range(len(idio_locate)): # other\n",
    "            r = idio_locate[i]\n",
    "            h_in_block[ (r,c)] += arr.iloc[f,i] # Get this right!\n",
    "    ######################################################################################################\n",
    "    ## DEPARTURE ANALYSIS\n",
    "    departures = pd.crosstab(these_paths['domain'],these_paths['to'])\n",
    "    # Shrink arrival rows to focus\n",
    "    row_names = departures.index.to_list()\n",
    "    col_names = departures\n",
    "    r_select = [ i in focus for i in row_names ] # Select only focus sites from rows of arrival\n",
    "    c_select = [ i not in focus for i in col_names ] # Select only focus sites from rows of arrival\n",
    "    dep = departures.iloc[r_select,c_select] # Shrink to focus sites\n",
    "    row_names = dep.index.to_list()\n",
    "    col_names = dep.columns\n",
    "    # Locate in larger array\n",
    "    focus_locate = [ focus.index(i) for i in row_names ] # focus sites\n",
    "    idio_locate = [ rolo_s.index(i) for i in col_names] # idio sites -- This is the major time cost\n",
    "    # Place values:\n",
    "    for f in range(len(focus_locate)):\n",
    "        c = focus_locate[f]\n",
    "        for i in range(len(idio_locate)):\n",
    "            r = idio_locate[i]\n",
    "            h_out_block[ (r,c)] += dep.iloc[f,i] # Get this right!\n",
    "    #print('Completed block: ', block_number, flush=True)\n",
    "    ###\n",
    "    result_path = '/scratch/trj2j/hmm/h/h_'\n",
    "    pickle.dump(h_in_block, open(result_path+'in_'+str(block_number)+'.pickle', 'wb'))\n",
    "    pickle.dump(h_out_block, open(result_path+'out_'+str(block_number)+'.pickle', 'wb'))\n",
    "    return block_number\n",
    "\n",
    "\n",
    "[ process_u_block( int(x) ) for x in out_remainder ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_u_block(block_number):\n",
    "    print('Processing block: ', block_number, flush=True)\n",
    "    assignment = pickle.load(open('/scratch/trj2j/hmm/site_allocations/assignment_'+str(block_number)+'.pickle','rb'))\n",
    "    this_block = assignment['this_block']\n",
    "    focus = assignment['focus']\n",
    "    K = len(focus)\n",
    "    rolo_s = assignment['rolo_s']\n",
    "    J = len(rolo_s)\n",
    "    path = \"/scratch/trj2j/hmm/u_paths/\"\n",
    "\n",
    "    ## Prep\n",
    "    h_in_block = lil_matrix((J,K), dtype=int) # other, focus\n",
    "    h_out_block = lil_matrix((J,K), dtype=int)\n",
    "\n",
    "    # Get all users in the block at once\n",
    "    these_paths = pd.DataFrame()\n",
    "    for u in this_block:\n",
    "        # Skip the really large path files    \n",
    "        path = \"/scratch/trj2j/hmm/u_paths/\"\n",
    "        file = 'path_'+str(u)+'.csv'\n",
    "        this_size = os.stat(os.path.join(path,file)).st_size\n",
    "        if this_size < 3000000: #4900000\n",
    "            user_path = pd.read_csv(path+file,low_memory=False)\n",
    "            these_paths = pd.concat([these_paths, user_path],axis=0)\n",
    "    ######################################################################################################\n",
    "    ## ARRIVAL ANALYSIS\n",
    "    arrivals = pd.crosstab(these_paths['domain'],these_paths['from'])\n",
    "    # Shrink arrival rows to focus\n",
    "    row_names = arrivals.index.to_list()\n",
    "    col_names = arrivals\n",
    "    r_select = [ i in focus for i in row_names ] # Select only focus sites from rows of arrival\n",
    "    c_select = [ i not in focus for i in col_names ] # Select only focus sites from rows of arrival\n",
    "    arr = arrivals.iloc[r_select,c_select] # Shrink to focus sites\n",
    "    row_names = arr.index.to_list()\n",
    "    col_names = arr.columns\n",
    "    # Locate in larger array\n",
    "    focus_locate = [ focus.index(i) for i in row_names ] # focus sites\n",
    "    idio_locate = [ rolo_s.index(i) for i in col_names] # idio sites -- This is the major time cost\n",
    "    # Place values in h_:\n",
    "    for f in range(len(focus_locate)): # focus\n",
    "        c = focus_locate[f]\n",
    "        for i in range(len(idio_locate)): # other\n",
    "            r = idio_locate[i]\n",
    "            h_in_block[ (r,c)] += arr.iloc[f,i] # Get this right!\n",
    "    ######################################################################################################\n",
    "    ## DEPARTURE ANALYSIS\n",
    "    departures = pd.crosstab(these_paths['domain'],these_paths['to'])\n",
    "    # Shrink arrival rows to focus\n",
    "    row_names = departures.index.to_list()\n",
    "    col_names = departures\n",
    "    r_select = [ i in focus for i in row_names ] # Select only focus sites from rows of arrival\n",
    "    c_select = [ i not in focus for i in col_names ] # Select only focus sites from rows of arrival\n",
    "    dep = departures.iloc[r_select,c_select] # Shrink to focus sites\n",
    "    row_names = dep.index.to_list()\n",
    "    col_names = dep.columns\n",
    "    # Locate in larger array\n",
    "    focus_locate = [ focus.index(i) for i in row_names ] # focus sites\n",
    "    idio_locate = [ rolo_s.index(i) for i in col_names] # idio sites -- This is the major time cost\n",
    "    # Place values:\n",
    "    for f in range(len(focus_locate)):\n",
    "        c = focus_locate[f]\n",
    "        for i in range(len(idio_locate)):\n",
    "            r = idio_locate[i]\n",
    "            h_out_block[ (r,c)] += dep.iloc[f,i] # Get this right!\n",
    "    #print('Completed block: ', block_number, flush=True)\n",
    "    ###\n",
    "    result_path = '/scratch/trj2j/hmm/h/h_'\n",
    "    pickle.dump(h_in_block, open(result_path+'in_'+str(block_number)+'.pickle', 'wb'))\n",
    "    pickle.dump(h_out_block, open(result_path+'out_'+str(block_number)+'.pickle', 'wb'))\n",
    "    return block_number\n",
    "\n",
    "\n",
    "[ process_u_block( int(x) ) for x in out_remainder ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "h_paths = os.listdir('/scratch/trj2j/hmm/h')\n",
    "in_vals = []\n",
    "out_vals = []\n",
    "\n",
    "for h in h_paths:\n",
    "    temp = re.split('[_.]', h)\n",
    "    if temp[1] == 'in':\n",
    "        in_vals.append(temp[2])\n",
    "    elif temp[1] == 'out':\n",
    "        out_vals.append(temp[2])\n",
    "\n",
    "all = [str(i) for i in range(N_blocks)]\n",
    "\n",
    "in_remainder = list(set(all)-set(in_vals))\n",
    "out_remainder = list(set(all)-set(out_vals))        \n",
    "\n",
    "print(in_remainder) # []\n",
    "print(out_remainder) # ['629', '1455']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing block:  0\n",
      "Processing block:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read/write error fix:\n",
    "[ process_u_block( int(x) ) for x in range(2) ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".hmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
